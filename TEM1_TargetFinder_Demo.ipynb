{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TEM-1 Target Finder (Demo)\n",
        "Predict binding to TEM-1 Î²-lactamase using small pretrained embeddings (ESM-2 for protein, ChemBERTa for ligands) + lightweight heads (XGBoost, LogisticRegression).\n",
        "\n",
        "Outputs **pAff (âˆ’log10 Kd)**, calibrated **P(binder)**, and simple graphs/heatmaps; runs on CPU.\n",
        "\n",
        "**Why this matters:** fast, docking-free triage of small molecules against a resistance enzyme."
      ],
      "metadata": {
        "id": "sdrep7z_OvLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Setup/Install"
      ],
      "metadata": {
        "id": "NVY9SYuBF630"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --no-cache-dir \\\n",
        "  torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip -q install --no-cache-dir \"transformers==4.44.2\" \"tokenizers==0.19.1\" \\\n",
        "  pandas==2.2.2 scikit-learn xgboost gradio requests"
      ],
      "metadata": {
        "id": "IbZP6m7HF5HE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, platform, numpy, torch, sklearn, transformers, xgboost, pandas, gradio\n",
        "print(\"Python:\", sys.version.split()[0], \"|\", platform.platform())\n",
        "print(\"NumPy:\", numpy.__version__)\n",
        "print(\"PyTorch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Transformers:\", transformers.__version__, \"| Tokenizers:\", transformers.__version__)\n",
        "print(\"scikit-learn:\", sklearn.__version__, \"| XGBoost:\", xgboost.__version__)\n",
        "print(\"pandas:\", pandas.__version__, \"| Gradio:\", gradio.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OtAfyRJSUmw",
        "outputId": "768b6b1e-d4d6-475e-c5cd-be5fb64d215a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.11.13 | Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "NumPy: 2.0.2\n",
            "PyTorch: 2.3.1+cpu | CUDA available: False\n",
            "Transformers: 4.44.2 | Tokenizers: 4.44.2\n",
            "scikit-learn: 1.6.1 | XGBoost: 3.0.3\n",
            "pandas: 2.2.2 | Gradio: 5.41.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Fetch protein sequence & generate ESM-2 embedding"
      ],
      "metadata": {
        "id": "qXV4JJAcGBe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch and clean the TEM-1 sequence from UniProt"
      ],
      "metadata": {
        "id": "fKTrbUZhS43F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch TEM-1 beta-lactamase protein sequence from UniProt\n",
        "import requests, re\n",
        "\n",
        "UNIPROT_ID = \"P62593\"\n",
        "fasta = requests.get(f\"https://rest.uniprot.org/uniprotkb/{UNIPROT_ID}.fasta\").text\n",
        "\n",
        "# Remove FASTA header and non-amino acid characters\n",
        "TEM1_SEQ = \"\".join(line.strip() for line in fasta.splitlines() if not line.startswith(\">\"))\n",
        "TEM1_SEQ = re.sub(r\"[^ACDEFGHIKLMNPQRSTVWY]\", \"\", TEM1_SEQ.upper())\n",
        "\n",
        "print(f\"TEM-1 length: {len(TEM1_SEQ)} amino acids\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXFta84LS036",
        "outputId": "e88e4c0e-92b1-4033-e7e2-abd0eaac4c4b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEM-1 length: 286 amino acids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a protein embedding with ESM-2 (35M)"
      ],
      "metadata": {
        "id": "qwPpY-Z5S7Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "# Select device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the lightweight ESM-2 model (12 layers, 35M parameters)\n",
        "tok_p = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
        "mdl_p = AutoModel.from_pretrained(\"facebook/esm2_t12_35M_UR50D\").to(device).eval()\n",
        "\n",
        "# Encode sequence into a mean-pooled embedding\n",
        "with torch.inference_mode():\n",
        "    toks = tok_p(TEM1_SEQ, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
        "    rep = mdl_p(**toks).last_hidden_state[0, 1:-1, :].mean(dim=0).cpu().numpy()\n",
        "\n",
        "# Store embedding as float32 (~480-D vector)\n",
        "prot_vec = rep.astype(np.float32)\n",
        "\n",
        "print(\"Protein embedding shape:\", prot_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhY_95A4S9dE",
        "outputId": "2fbc3e73-5800-4aba-ca2b-c011962bc5f4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protein embedding shape: (480,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Load ligand dataset & prepare scaffolds"
      ],
      "metadata": {
        "id": "PKlQz4nnGOF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload CSV file from local machine\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # pick tem1_clean.csv\n",
        "\n",
        "csv_path = [k for k in uploaded.keys() if k.endswith(\".csv\")][0]\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Compute Bemisâ€“Murcko scaffolds if missing\n",
        "if \"scaffold\" not in df.columns:\n",
        "    def murcko_scaffold(smi):\n",
        "        m = Chem.MolFromSmiles(str(smi))\n",
        "        return MurckoScaffold.MurckoScaffoldSmiles(mol=m) if m else None\n",
        "    df[\"scaffold\"] = df[\"smiles\"].apply(murcko_scaffold)\n",
        "\n",
        "# Data sanity check\n",
        "needed = {\"smiles\",\"pAff\"}\n",
        "missing = needed - set(df.columns)\n",
        "assert not missing, f\"Missing columns: {missing}\"\n",
        "df = df.dropna(subset=[\"smiles\",\"pAff\"]).reset_index(drop=True)\n",
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "dEQpfDnbGK45",
        "outputId": "135f66ca-59cb-4a67-bbc2-4a43c09c255b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-abaa62e3-2d22-430a-8595-0d8a55d69feb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-abaa62e3-2d22-430a-8595-0d8a55d69feb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tem1_clean.csv to tem1_clean.csv\n",
            "(316, 11)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              smiles  affinity_nM      pAff  \\\n",
              "0     [O-]C(=O)C1=CS[C@H]2N1C(=O)\\C2=C/c1cn2CCOCc2n1         0.40  9.397940   \n",
              "1     [O-]C(=O)C1=CS[C@H]2N1C(=O)\\C2=C\\c1cnc2COCCn12         0.40  9.397940   \n",
              "2  CC1=C[C@H](N2C[C@@H]1N(OC(F)(F)C(O)=O)C2=O)C(N)=O         0.47  9.327902   \n",
              "\n",
              "  affinity_type uniprot_id         target_name  organism  \\\n",
              "0          IC50     P62593  Beta-lactamase TEM       NaN   \n",
              "1          IC50     P62593  Beta-lactamase TEM       NaN   \n",
              "2          IC50     P62593  Beta-lactamase TEM       NaN   \n",
              "\n",
              "                                         ligand_name  ligand_id        pmid  \\\n",
              "0  CHEMBL212163::sodium (R,E)-6-((6,8-dihydro-5H-...   50191378  16854068.0   \n",
              "1  CHEMBL263746::Sodium; (R)-6-[1-(5,6-dihydro-8H...   50149468  15214794.0   \n",
              "2  2-(((2S,5R)-2-carbamoyl-4-methyl-7-oxo-1,6-dia...     467000         NaN   \n",
              "\n",
              "                            scaffold  \n",
              "0  O=C1C(=Cc2cn3c(n2)COCC3)C2SC=CN12  \n",
              "1    O=C1C(=Cc2cnc3n2CCOC3)C2SC=CN12  \n",
              "2                    O=C1NC2C=CCN1C2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbf014f5-4efd-4d7f-8213-e72e462c5e8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>affinity_nM</th>\n",
              "      <th>pAff</th>\n",
              "      <th>affinity_type</th>\n",
              "      <th>uniprot_id</th>\n",
              "      <th>target_name</th>\n",
              "      <th>organism</th>\n",
              "      <th>ligand_name</th>\n",
              "      <th>ligand_id</th>\n",
              "      <th>pmid</th>\n",
              "      <th>scaffold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[O-]C(=O)C1=CS[C@H]2N1C(=O)\\C2=C/c1cn2CCOCc2n1</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.397940</td>\n",
              "      <td>IC50</td>\n",
              "      <td>P62593</td>\n",
              "      <td>Beta-lactamase TEM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CHEMBL212163::sodium (R,E)-6-((6,8-dihydro-5H-...</td>\n",
              "      <td>50191378</td>\n",
              "      <td>16854068.0</td>\n",
              "      <td>O=C1C(=Cc2cn3c(n2)COCC3)C2SC=CN12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[O-]C(=O)C1=CS[C@H]2N1C(=O)\\C2=C\\c1cnc2COCCn12</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.397940</td>\n",
              "      <td>IC50</td>\n",
              "      <td>P62593</td>\n",
              "      <td>Beta-lactamase TEM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CHEMBL263746::Sodium; (R)-6-[1-(5,6-dihydro-8H...</td>\n",
              "      <td>50149468</td>\n",
              "      <td>15214794.0</td>\n",
              "      <td>O=C1C(=Cc2cnc3n2CCOC3)C2SC=CN12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC1=C[C@H](N2C[C@@H]1N(OC(F)(F)C(O)=O)C2=O)C(N)=O</td>\n",
              "      <td>0.47</td>\n",
              "      <td>9.327902</td>\n",
              "      <td>IC50</td>\n",
              "      <td>P62593</td>\n",
              "      <td>Beta-lactamase TEM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2-(((2S,5R)-2-carbamoyl-4-methyl-7-oxo-1,6-dia...</td>\n",
              "      <td>467000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>O=C1NC2C=CCN1C2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbf014f5-4efd-4d7f-8213-e72e462c5e8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbf014f5-4efd-4d7f-8213-e72e462c5e8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbf014f5-4efd-4d7f-8213-e72e462c5e8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b1df830f-b46a-4802-bff2-4ff04a86c6b1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1df830f-b46a-4802-bff2-4ff04a86c6b1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b1df830f-b46a-4802-bff2-4ff04a86c6b1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 316,\n  \"fields\": [\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 316,\n        \"samples\": [\n          \"COc1ccc2B(O)OC(c2c1)c1ccc(cc1)N(C)C\",\n          \"[O-]C(=O)C1=CS[C@H]2N1C(=O)\\\\C2=C\\\\c1cc2OCCCn2n1\",\n          \"CC(C)(C)C(=O)OCOC(=O)C1(CC=Cc2ccccc2)N2[C@@H](CC2=O)OC1=CC=O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affinity_nM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122264381.49337871,\n        \"min\": 0.4,\n        \"max\": 2147483647.0,\n        \"num_unique_values\": 258,\n        \"samples\": [\n          65.5,\n          30.6,\n          1.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pAff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8305741898322687,\n        \"min\": -0.3319298653811829,\n        \"max\": 9.397940008672036,\n        \"num_unique_values\": 258,\n        \"samples\": [\n          7.183758700008217,\n          7.51427857351842,\n          8.744727494896694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affinity_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ki\",\n          \"IC50\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"uniprot_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"P62593\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Beta-lactamase TEM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"organism\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ligand_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 316,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ligand_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22350110,\n        \"min\": 26126,\n        \"max\": 50569224,\n        \"num_unique_values\": 316,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pmid\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 31,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scaffold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 105,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Ligand Embedding with ChemBERTa & Feature Combination"
      ],
      "metadata": {
        "id": "It0F7O0RGl2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load ChemBERTa model"
      ],
      "metadata": {
        "id": "U65R4JX4T_t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, torch, time\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Use GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load ChemBERTa (ligand encoder)\n",
        "tok_l = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
        "mdl_l = AutoModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\").to(device).eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXjSVkijT_Mn",
        "outputId": "9a61e5f9-04bf-4573-dcec-9c38fccde4da"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define embedding function for SMILES"
      ],
      "metadata": {
        "id": "GSPfzPV7UDi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chemberta_embed(smiles_list, batch_size=64, max_length=256):\n",
        "    \"\"\"\n",
        "    Generate ligand embeddings from SMILES strings using ChemBERTa.\n",
        "    - Uses CLS token representation as molecule embedding.\n",
        "    - Processes molecules in batches for speed.\n",
        "    \"\"\"\n",
        "    vecs = []\n",
        "    for i in range(0, len(smiles_list), batch_size):\n",
        "        batch = smiles_list[i:i+batch_size]\n",
        "        enc = tok_l(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
        "        with torch.inference_mode():\n",
        "            out = mdl_l(**enc).last_hidden_state  # Shape: [B, L, D]\n",
        "            cls = out[:, 0, :].detach().cpu().numpy().astype(np.float32)  # CLS token vector\n",
        "        vecs.append(cls)\n",
        "    return np.vstack(vecs)\n"
      ],
      "metadata": {
        "id": "tYBT0Q-nUFbc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embed ligands & combine with protein embedding"
      ],
      "metadata": {
        "id": "P-nZB17JUIH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate ligand embeddings (~768-D)\n",
        "t0 = time.time()\n",
        "lig_X = chemberta_embed(df[\"smiles\"].tolist(), batch_size=64)\n",
        "print(\"Ligand embed:\", lig_X.shape, f\"in {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Repeat protein embedding for each ligand (~480-D)\n",
        "prot_X = np.repeat(prot_vec.reshape(1, -1), len(df), axis=0)\n",
        "\n",
        "# Combine protein and ligand embeddings (~1248-D feature space)\n",
        "X = np.hstack([prot_X, lig_X]).astype(np.float32)\n",
        "\n",
        "# Labels: continuous pAff and binary binder classification\n",
        "y = df[\"pAff\"].values.astype(np.float32)\n",
        "y_bin = (y >= 6.0).astype(np.int32)\n",
        "print(\"X:\", X.shape, \"| binders:\", int(y_bin.sum()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU96pU-PUKJs",
        "outputId": "170346fc-10a1-42a0-d7df-8626576cb2f6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ligand embed: (316, 768) in 40.7s\n",
            "X: (316, 1248) | binders: 170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Scaffold-/Cluster-Aware Data Splitting & Model Training"
      ],
      "metadata": {
        "id": "1HEaLcgTGqXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why:\n",
        "To ensure realistic evaluation, we split the dataset so that structurally similar ligands (same scaffold or same cluster) do not appear in both train and test sets. This prevents data leakage and ensures that the model is tested on truly novel chemical structures.\n",
        "\n",
        "We then train two models:\n",
        "\n",
        "*   XGBoost Regressor â†’ Predict continuous binding\n",
        "*   Logistic Regression â†’ Predict binary \"binder vs non-binder\" labels"
      ],
      "metadata": {
        "id": "GqY8xKTYVZhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group-wise train/test split"
      ],
      "metadata": {
        "id": "Zdu9JUbrVq7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def groupwise_split(groups, test_frac=0.2, seed=7):\n",
        "    \"\"\"\n",
        "    Splits dataset into train/test groups based on scaffolds or clusters.\n",
        "    Ensures no scaffold appears in both sets.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    buckets = {}\n",
        "    for i, g in enumerate(groups):\n",
        "        key = str(g) if (g and str(g).strip()) else f\"None_{i}\"\n",
        "        buckets.setdefault(key, []).append(i)\n",
        "    keys = list(buckets.keys())\n",
        "    rng.shuffle(keys)\n",
        "\n",
        "    test_idx, taken = [], 0\n",
        "    N = len(groups)\n",
        "    for k in keys:\n",
        "        if taken / N < test_frac:\n",
        "            test_idx.extend(buckets[k])\n",
        "            taken += len(buckets[k])\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    train_idx = sorted(set(range(N)) - set(test_idx))\n",
        "    return np.array(train_idx), np.array(test_idx)\n",
        "\n",
        "# Group by scaffold (if available) or cluster in embedding space\n",
        "if \"scaffold\" in df.columns and df[\"scaffold\"].notna().sum() > 0:\n",
        "    groups = df[\"scaffold\"].fillna(\"\").tolist()\n",
        "else:\n",
        "    k = max(5, min(50, len(df) // 50))  # adaptive # clusters\n",
        "    km = KMeans(n_clusters=k, random_state=7, n_init=10)\n",
        "    groups = km.fit_predict(lig_X).tolist()\n",
        "\n",
        "# Perform group-wise split\n",
        "tr_idx, te_idx = groupwise_split(groups, test_frac=0.2, seed=7)\n",
        "\n",
        "# Create split datasets\n",
        "X_tr, X_te = X[tr_idx], X[te_idx]\n",
        "y_tr, y_te = y[tr_idx], y[te_idx]\n",
        "yb_tr, yb_te = y_bin[tr_idx], y_bin[te_idx]\n",
        "\n",
        "print(f\"train={len(tr_idx)} (binders {yb_tr.sum()}) | test={len(te_idx)} (binders {yb_te.sum()})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeCNs0szVuHN",
        "outputId": "72eb31d5-f211-47c0-e30e-453afdcc91b1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train=241 (binders 141) | test=75 (binders 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train models & evaluate"
      ],
      "metadata": {
        "id": "kvmZhF8_VyMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, average_precision_score\n",
        "\n",
        "reg = XGBRegressor(\n",
        "    n_estimators=600, max_depth=6, learning_rate=0.05,\n",
        "    subsample=0.8, colsample_bytree=0.8, n_jobs=-1\n",
        ").fit(X_tr, y_tr)\n",
        "\n",
        "pred = reg.predict(X_te)\n",
        "try:\n",
        "    rmse = mean_squared_error(y_te, pred, squared=False)\n",
        "except TypeError:\n",
        "    rmse = mean_squared_error(y_te, pred) ** 0.5\n",
        "r2 = r2_score(y_te, pred)\n",
        "\n",
        "clf = LogisticRegression(max_iter=2000).fit(X_tr, yb_tr)\n",
        "p_bin = clf.predict_proba(X_te)[:, 1]\n",
        "roc = roc_auc_score(yb_te, p_bin)\n",
        "pr  = average_precision_score(yb_te, p_bin)\n",
        "\n",
        "print({\"RMSE\": round(float(rmse),3),\n",
        "       \"R2\": round(float(r2),3),\n",
        "       \"ROC-AUC\": round(float(roc),3),\n",
        "       \"PR-AUC\": round(float(pr),3)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck_Lgn6WV00K",
        "outputId": "e93a2393-4ad3-442f-c89f-279b9eb7ad77"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'RMSE': 1.996, 'R2': 0.227, 'ROC-AUC': 0.968, 'PR-AUC': 0.933}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Final Gradio UI â€” Prediction logic, uncertainty, calibration"
      ],
      "metadata": {
        "id": "ccp5iQLVXCQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helpers â€” units & prediction-interval lookup"
      ],
      "metadata": {
        "id": "c7pVAKkSZ5b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helpers: pAff â†” concentration (nM) formatting\n",
        "import numpy as np\n",
        "\n",
        "def pAff_to_nM(p):\n",
        "    return 1e9 * (10 ** (-p))\n",
        "\n",
        "def fmt_conc(nM):\n",
        "    if nM < 1e-2:   return f\"{nM*1e3:.2f} pM\"\n",
        "    if nM < 1:      return f\"{nM:.2f} nM\"\n",
        "    if nM < 1e3:    return f\"{nM/1e3:.2f} ÂµM\"\n",
        "    return f\"{nM/1e6:.2f} mM\"\n",
        "\n",
        "# Ensure test preds exist (used to build conditional 90% intervals)\n",
        "try:\n",
        "    pred\n",
        "except NameError:\n",
        "    pred = reg.predict(X_te)\n",
        "\n",
        "# Conditional 90% absolute error by predicted pAff bin\n",
        "bins = np.linspace(float(pred.min()), float(pred.max()), 8)\n",
        "bin_idx = np.digitize(pred, bins)\n",
        "global_q90 = float(np.quantile(np.abs(y_te - pred), 0.90))\n",
        "\n",
        "q90_table = []\n",
        "for b in range(len(bins)+1):\n",
        "    m = bin_idx == b\n",
        "    if m.sum() >= 15:\n",
        "        q90_table.append(float(np.quantile(np.abs(y_te[m] - pred[m]), 0.90)))\n",
        "    else:\n",
        "        q90_table.append(global_q90)\n",
        "\n",
        "def q90_for(p):\n",
        "    i = int(np.digitize([p], bins)[0])\n",
        "    i = max(0, min(i, len(q90_table)-1))\n",
        "    return q90_table[i]"
      ],
      "metadata": {
        "id": "8Lm4_tZTZ4-0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calibration & distribution-shift check"
      ],
      "metadata": {
        "id": "PU4x856rZ9QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibrate classifier probabilities (isotonic) on training data\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "\n",
        "HI, MID = 0.80, 0.60  # Likely / Uncertain thresholds\n",
        "\n",
        "# Avoid name shadowing: keep original 'clf' and create a calibrated wrapper\n",
        "clf_cal = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3).fit(X_tr, yb_tr)\n",
        "\n",
        "def conf_label(p): return \"Likely\" if p >= HI else (\"Uncertain\" if p >= MID else \"Unlikely\")\n",
        "def conf_emoji(p): return \"ðŸŸ¢\" if p >= HI else (\"ðŸŸ¡\" if p >= MID else \"ðŸ”´\")\n",
        "\n",
        "# In-distribution check: nearest ligand similarity in training set (ChemBERTa space)\n",
        "prot_dim = prot_vec.shape[0]\n",
        "lig_tr   = X_tr[:, prot_dim:]  # ligand features only\n",
        "\n",
        "def train_similarity(smiles):\n",
        "    enc = tok_l([smiles], padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(device)\n",
        "    with torch.inference_mode():\n",
        "        lig = mdl_l(**enc).last_hidden_state[:,0,:].cpu().numpy().astype(np.float32)\n",
        "    sim = cosine_similarity(lig, lig_tr)[0]\n",
        "    return float(sim.max())"
      ],
      "metadata": {
        "id": "bDuGzuzzZ-4c"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictor used by the UI"
      ],
      "metadata": {
        "id": "aHp3OLQAaAqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict for a single SMILES: pAff + 90% PI + calibrated P(binder) + similarity note\n",
        "def predict_smiles(smiles: str):\n",
        "    if not smiles:\n",
        "        return \"Please enter a SMILES\", \"\"\n",
        "\n",
        "    # 1) ChemBERTa ligand embedding\n",
        "    enc = tok_l([smiles], padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(device)\n",
        "    with torch.inference_mode():\n",
        "        out = mdl_l(**enc).last_hidden_state\n",
        "        lig = out[:, 0, :].detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "    # 2) Build joint feature with TEM-1 (WT) protein embedding\n",
        "    fx = np.hstack([prot_vec.reshape(1, -1), lig]).astype(np.float32)\n",
        "\n",
        "    # 3) Regression â†’ pAff and conditional 90% interval\n",
        "    p_aff = float(reg.predict(fx)[0])\n",
        "    q90   = q90_for(p_aff)\n",
        "    p_lo, p_hi = p_aff - q90, p_aff + q90\n",
        "\n",
        "    # Pretty concentration readouts\n",
        "    nM_center = pAff_to_nM(p_aff)\n",
        "    nM_hi, nM_lo = pAff_to_nM(p_hi), pAff_to_nM(p_lo)\n",
        "\n",
        "    # 4) Calibrated binder probability and label\n",
        "    p_cal = float(clf_cal.predict_proba(fx)[:, 1])\n",
        "    label = conf_label(p_cal); mark = conf_emoji(p_cal)\n",
        "    badge = \" (â‰¤1 ÂµM)\" if p_aff >= 6 else \"\"\n",
        "\n",
        "    # 5) Training-set similarity (OOD cue)\n",
        "    sim = train_similarity(smiles)\n",
        "    sim_note = (f\"\\nNearest-set similarity: {sim:.2f}\"\n",
        "                if sim >= 0.60 else\n",
        "                f\"\\nâš ï¸ Low training similarity (cosine={sim:.2f}) â€” higher uncertainty.\")\n",
        "\n",
        "    # 6) Final message (compact but informative)\n",
        "    msg = (\n",
        "        f\"{mark} **pAff={p_aff:.2f}** (â‰ˆ {fmt_conc(nM_center)}) â€¢ \"\n",
        "        f\"90%â‰ˆ[{p_lo:.2f}, {p_hi:.2f}] (â‰ˆ {fmt_conc(nM_hi)}â€“{fmt_conc(nM_lo)})\\n\"\n",
        "        f\"**P(binder)={p_cal:.2f} â†’ {label}**{badge} \"\n",
        "        f\"[Likelyâ‰¥{HI:.2f}, Uncertain {MID:.2f}â€“{HI:.2f}, Unlikely<{MID:.2f}]\"\n",
        "        + sim_note\n",
        "    )\n",
        "    return msg, smiles"
      ],
      "metadata": {
        "id": "3GH607xIaC60"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helpers for Batch Prediction & Parsing"
      ],
      "metadata": {
        "id": "km-VYV55ah6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, numpy as np, matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def _parse_smiles_block(text, limit=100):\n",
        "    smi = [s.strip() for s in re.split(r'[\\n,;]+', str(text or \"\")) if s.strip()]\n",
        "    return smi[:limit]\n",
        "\n",
        "def _embed_ligands(smiles_list):\n",
        "    enc = tok_l(smiles_list, padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(device)\n",
        "    with torch.inference_mode():\n",
        "        out = mdl_l(**enc).last_hidden_state\n",
        "        ligs = out[:, 0, :].detach().cpu().numpy().astype(np.float32)\n",
        "    return ligs  # (L, D)\n",
        "\n",
        "def batch_predict(smiles_text):\n",
        "    smi = _parse_smiles_block(smiles_text)\n",
        "    if not smi:\n",
        "        return [], np.array([]), np.array([])\n",
        "    lig = _embed_ligands(smi)                              # (L, Dl)\n",
        "    P   = np.repeat(prot_vec.reshape(1, -1), len(smi), 0)  # (L, Dp)\n",
        "    X   = np.hstack([P, lig]).astype(np.float32)           # (L, Dp+Dl)\n",
        "    p_aff  = reg.predict(X)\n",
        "    p_bind = clf.predict_proba(X)[:, 1]\n",
        "    return smi, p_aff, p_bind\n"
      ],
      "metadata": {
        "id": "iyTd3__65GPK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Functions"
      ],
      "metadata": {
        "id": "pCnB0bTQapPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_paff_bars(smiles_text, top_n=20, paff_threshold=6.0):\n",
        "    names, paff, pbind = batch_predict(smiles_text)\n",
        "    fig = plt.figure(figsize=(10, max(3, 0.35 * max(1, len(names)))))\n",
        "    if len(names) == 0:\n",
        "        plt.text(0.5, 0.5, \"Provide one or more SMILES\", ha=\"center\", va=\"center\")\n",
        "        plt.axis(\"off\"); return fig\n",
        "\n",
        "    idx = np.argsort(-paff)[:top_n]\n",
        "    names = [names[i] for i in idx]; paff = paff[idx]; pbind = pbind[idx]\n",
        "\n",
        "    y = np.arange(len(names))\n",
        "    plt.barh(y, paff)\n",
        "    plt.axvline(paff_threshold, linestyle=\"--\")  # â‰ˆ 1 ÂµM\n",
        "    for i, (x, pb) in enumerate(zip(paff, pbind)):\n",
        "        plt.text(x, i, f\"  p={pb:.2f}\", va=\"center\")\n",
        "    plt.yticks(y, [n[:45] + (\"â€¦\" if len(n) > 45 else \"\") for n in names])\n",
        "    plt.xlabel(\"Predicted pAff  (âˆ’log10 M) â€” higher = tighter\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def plot_paff_vs_pbind(smiles_text, hi=0.80, mid=0.60, paff_thr=6.0):\n",
        "    names, paff, pbind = batch_predict(smiles_text)\n",
        "    fig = plt.figure(figsize=(7, 5))\n",
        "    if len(names) == 0:\n",
        "        plt.text(0.5, 0.5, \"Provide one or more SMILES\", ha=\"center\", va=\"center\")\n",
        "        plt.axis(\"off\"); return fig\n",
        "\n",
        "    plt.scatter(paff, pbind, s=36)\n",
        "    plt.axvline(paff_thr, linestyle=\"--\"); plt.axhline(hi, linestyle=\"--\"); plt.axhline(mid, linestyle=\"--\")\n",
        "    # annotate a few promising points\n",
        "    top = np.argsort(-(paff + pbind))[:10]\n",
        "    for i in top:\n",
        "        lbl = names[i][:18] + (\"â€¦\" if len(names[i]) > 18 else \"\")\n",
        "        plt.annotate(lbl, (paff[i], pbind[i]), xytext=(4, 4), textcoords=\"offset points\")\n",
        "    plt.xlabel(\"Predicted pAff (âˆ’log10 M)\"); plt.ylabel(\"Calibrated P(binder)\")\n",
        "    plt.title(\"Batch predictions\"); plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def plot_eval_true_vs_pred():\n",
        "    try:\n",
        "        y_true = y_te\n",
        "        y_pred = reg.predict(X_te)\n",
        "    except Exception:\n",
        "        fig = plt.figure(figsize=(6, 2))\n",
        "        plt.text(0.5, 0.5, \"No held-out set available in this session.\", ha=\"center\", va=\"center\")\n",
        "        plt.axis(\"off\"); return fig\n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "    plt.scatter(y_true, y_pred, s=20, alpha=0.7)\n",
        "    lo = float(min(y_true.min(), y_pred.min())); hi = float(max(y_true.max(), y_pred.max()))\n",
        "    plt.plot([lo, hi], [lo, hi], linestyle=\"--\")\n",
        "    plt.xlabel(\"True pAff\"); plt.ylabel(\"Predicted pAff\"); plt.title(\"Held-out evaluation\")\n",
        "    plt.tight_layout(); return fig"
      ],
      "metadata": {
        "id": "OJp_8wpf5INy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmap Predictor: Batch SMILES Affinity Map (WT TEM-1)"
      ],
      "metadata": {
        "id": "VYoJr-SFaw-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, numpy as np, torch, matplotlib.pyplot as plt\n",
        "\n",
        "def heatmap_predict(smiles_text):\n",
        "    smi_list = [s.strip() for s in re.split(r'[\\n,;]+', str(smiles_text)) if s.strip()]\n",
        "    smi_list = smi_list[:20]\n",
        "    if not smi_list:\n",
        "        return None\n",
        "\n",
        "    # Batch ChemBERTa embeddings\n",
        "    enc = tok_l(smi_list, padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(device)\n",
        "    with torch.inference_mode():\n",
        "        out = mdl_l(**enc).last_hidden_state\n",
        "        ligs = out[:, 0, :].detach().cpu().numpy().astype(np.float32)  # (L, D)\n",
        "\n",
        "    pv = prot_vec.reshape(1, -1)\n",
        "    pv_rep = np.repeat(pv, len(smi_list), axis=0)\n",
        "    fx = np.hstack([pv_rep, ligs]).astype(np.float32)\n",
        "    p_affs = reg.predict(fx)  # (L,)\n",
        "\n",
        "    M = p_affs.reshape(1, -1)  # single row: WT only\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(max(6, len(smi_list)*0.8), 2.8))\n",
        "    im = ax.imshow(M, aspect=\"auto\")\n",
        "    ax.set_xticks(range(len(smi_list)))\n",
        "    ax.set_xticklabels([s[:14] + (\"â€¦\" if len(s) > 14 else \"\") for s in smi_list], rotation=45, ha=\"right\")\n",
        "    ax.set_yticks([0]); ax.set_yticklabels([\"TEM-1 (WT)\"])\n",
        "    cbar = fig.colorbar(im, ax=ax); cbar.set_label(\"Predicted pAff\")\n",
        "\n",
        "    for j in range(M.shape[1]):\n",
        "        if M[0, j] >= 6.0:\n",
        "            ax.text(j, 0, \"â˜…\", ha=\"center\", va=\"center\", fontsize=8)\n",
        "\n",
        "    ax.set_xlabel(\"Ligands\"); ax.set_ylabel(\"Variant\")\n",
        "    fig.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "xnEKfqTPsrRZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Interactive Gradio App (Demo)"
      ],
      "metadata": {
        "id": "mAKefWJpGwDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr, numpy as np, torch\n",
        "\n",
        "# --- tolerant access to thresholds/metrics so UI renders even if they don't exist yet ---\n",
        "HI_T  = float(globals().get(\"HI\", 0.80))\n",
        "MID_T = float(globals().get(\"MID\", 0.60))\n",
        "_rmse = globals().get(\"rmse\", None)\n",
        "_r2   = globals().get(\"r2\", None)\n",
        "_roc  = globals().get(\"roc\", None)\n",
        "_pr   = globals().get(\"pr\", None)\n",
        "\n",
        "metrics_md = (\n",
        "    f\"**Eval (held-out)** â€” RMSE: {_rmse:.2f} pAff (â‰ˆÃ—{10**_rmse:.1f}), \"\n",
        "    f\"RÂ²: {_r2:.2f}, ROC-AUC: {_roc:.2f}, PR-AUC: {_pr:.2f}\"\n",
        "    if all(v is not None for v in [_rmse, _r2, _roc, _pr])\n",
        "    else \"*(Train a model or run evaluation to populate metrics here.)*\"\n",
        ")\n",
        "\n",
        "# --- a tiny helper to clear inputs/outputs (nice for live demos) ---\n",
        "def _clear_inputs():\n",
        "    return \"\", \"\", \"\",\"\"\n",
        "\n",
        "with gr.Blocks(title=\"Antibiotic Resistance Target Finder â€” TEM-1\") as demo:\n",
        "    # ===== Header / quick intro =====\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "# Antibiotic Resistance Target Finder â€” TEM-1\n",
        "**Goal:** Predict how tightly a small molecule binds **TEM-1 Î²-lactamase** variants (antibiotic resistance enzyme).\n",
        "\n",
        "**How to use (2 steps):**\n",
        "1) Paste a **SMILES** string and click **Submit** to get a prediction.\n",
        "2) Explore **heatmaps** and **binding-affinity graphs** for batches of SMILES.\n",
        "\n",
        "*Protein embeddings:* ESM-2 (35M)â€ƒâ€¢â€ƒ*Ligand embeddings:* ChemBERTaâ€ƒâ€¢â€ƒ*Models:* small XGBoost + LogisticRegression\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # ===== INPUT + PREDICTION =====\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### 1) Enter a molecule (SMILES)\")\n",
        "            inp = gr.Textbox(\n",
        "                label=\"SMILES\",\n",
        "                placeholder=\"e.g., CCO    (ethanol)\",\n",
        "                lines=1,\n",
        "            )\n",
        "            gr.Examples(\n",
        "                label=\"Try examples\",\n",
        "                examples=[\n",
        "                    [\"CCO\"],  # unlikely binder\n",
        "                    [\"[O-]C(=O)C1=CS[C@H]2N1C(=O)\\\\C2=C/c1cn2CCOCc2n1\"],  # strong-ish example\n",
        "                    [\"CC1=C[C@H](N2C[C@@H]1N(OC(F)(F)C(O)=O)C2=O)C(N)=O\"], # moderate example\n",
        "                ],\n",
        "                inputs=[inp],\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                btn = gr.Button(\"ðŸš€ Submit\", variant=\"primary\")\n",
        "                clr = gr.Button(\"Clear\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            gr.Markdown(\"### 2) Model output\")\n",
        "            out_pred = gr.Markdown(label=\"Prediction\")\n",
        "            out_smi  = gr.Textbox(label=\"Echoed SMILES\", interactive=False)\n",
        "\n",
        "            # Quick legend so judges instantly understand labels\n",
        "            gr.Markdown(\n",
        "                f\"\"\"\n",
        "**How to read this:**\n",
        "- **pAff** = âˆ’log10(Kd) in molar (higher â‡’ tighter).\n",
        "  6 â‰ˆ 1 ÂµM, 7 â‰ˆ 100 nM, 8 â‰ˆ 10 nM, 9 â‰ˆ 1 nM.\n",
        "- **P(binder)** is a calibrated probability.\n",
        "  We label as **Likely** (â‰¥ {HI_T:.2f}), **Uncertain** ({MID_T:.2f}â€“{HI_T:.2f}), **Unlikely** (< {MID_T:.2f}).\n",
        "- We also show a nearest-neighbor similarity to flag **distribution shift** (low similarity â‡’ higher uncertainty).\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "    # wire prediction + clear\n",
        "    btn.click(predict_smiles, [inp], [out_pred, out_smi])\n",
        "    clr.click(_clear_inputs, outputs=[inp, out_smi, ], inputs=None)\n",
        "\n",
        "    # ===== EXPLANATION ACCORDIONS =====\n",
        "    with gr.Accordion(\"What is pAff and why âˆ’log10?\", open=False):\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "**pAff** is the negative log10 of affinity in molar (e.g., Kd).\n",
        "We use âˆ’log10(Kd) because itâ€™s easy to compare (bigger is better), and it keeps values in a compact 5â€“10 range.\n",
        "\n",
        "**Examples**\n",
        "- 1 ÂµM â†’ pAff=6\n",
        "- 100 nM â†’ pAff=7\n",
        "- 10 nM â†’ pAff=8\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with gr.Accordion(\"How this model works (1-paragraph)\", open=False):\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "**Embeddings:** ESM-2 (35M) encodes the protein; ChemBERTa encodes the ligand.\n",
        "We concatenate embeddings and train (a) **XGBoost** for pAff and (b) **LogisticRegression** for P(binder).\n",
        "This keeps compute tiny while leveraging powerful pre-training.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    # ===== HEATMAP (WT only, quick batch view) =====\n",
        "    with gr.Accordion(\"Ligand heatmap (WT only)\", open=False):\n",
        "        gr.Markdown(\n",
        "            \"Paste multiple SMILES to see a quick heatmap of predicted pAff (TEM-1 wild-type).\"\n",
        "        )\n",
        "        smi_multi = gr.Textbox(\n",
        "            label=\"SMILES list (comma or newline separated)\",\n",
        "            lines=4,\n",
        "            placeholder=\"CCO\\nc1ccccc1\\n[O-]C(=O)C1=CS[C@H]2N1C(=O)\\\\C2=C/c1cn2CCOCc2n1\",\n",
        "            value=\"CCO\\nc1ccccc1\\n[O-]C(=O)C1=CS[C@H]2N1C(=O)\\\\C2=C/c1cn2CCOCc2n1\",\n",
        "        )\n",
        "        hm_btn = gr.Button(\"Build heatmap\")\n",
        "        hm_plot = gr.Plot(label=\"pAff heatmap\")\n",
        "        hm_btn.click(heatmap_predict, [smi_multi], hm_plot)\n",
        "\n",
        "    # ===== BINDING-AFFINITY GRAPHS (bar / scatter / eval) =====\n",
        "    with gr.Accordion(\"Binding-affinity graphs\", open=True):\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "**Why these graphs?**\n",
        "- **Bar chart:** rank molecules by predicted pAff (quick top-N).\n",
        "- **Scatter:** shows pAff vs **P(binder)** (agreement helps trust; disagreements signal uncertainty).\n",
        "- **Eval plot (optional):** if ground truth is loaded, compare predicted vs true.\n",
        "            \"\"\"\n",
        "        )\n",
        "        smi_batch = gr.Textbox(\n",
        "            label=\"SMILES list (newline or comma separated)\",\n",
        "            lines=4,\n",
        "            placeholder=\"CCO\\nc1ccccc1\\n[O-]C(=O)C1=CS[C@H]2N1C(=O)\\\\C2=C/c1cn2CCOCc2n1\",\n",
        "            value=\"CCO\\nc1ccccc1\\n[O-]C(=O)C1=CS[C@H]2N1C(=O)\\\\C2=C/c1cn2CCOCc2n1\",\n",
        "        )\n",
        "        with gr.Row():\n",
        "            bar_btn  = gr.Button(\"Top-N pAff bar chart\")\n",
        "            scat_btn = gr.Button(\"pAff vs P(binder) scatter\")\n",
        "            eval_btn = gr.Button(\"Eval: true vs predicted\")\n",
        "        out_plot = gr.Plot(label=\"Graph\")\n",
        "\n",
        "        # wire actions (your plotting fns must already exist)\n",
        "        bar_btn.click(lambda s: plot_paff_bars(s, top_n=20), [smi_batch], out_plot)\n",
        "        scat_btn.click(plot_paff_vs_pbind, [smi_batch], out_plot)\n",
        "        eval_btn.click(lambda: plot_eval_true_vs_pred(), [], out_plot)\n",
        "\n",
        "    # ===== Model card / metrics / limitations =====\n",
        "    with gr.Accordion(\"Model card: assumptions, metrics & limits\", open=False):\n",
        "        gr.Markdown(\n",
        "            f\"\"\"\n",
        "**Compute footprint:** small (â‰¤50M embeddings + lightweight heads). Runs on CPU in Colab/Spaces.\n",
        "{metrics_md}\n",
        "\n",
        "**Assumptions / caveats**\n",
        "- Trained on **TEM-1** datasets; predictions for very dissimilar chemotypes are less certain.\n",
        "- Reported â€œconfidenceâ€ is **calibrated** on a held-out set; not a substitute for wet-lab validation.\n",
        "- Use as a **ranking/triage** tool, not as a definitive activity claim.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "ns8Cr_kI9VCq",
        "outputId": "b0e5e698-6144-4e37-a95a-156477b50619"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cda9106cdd3e369ee0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cda9106cdd3e369ee0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}